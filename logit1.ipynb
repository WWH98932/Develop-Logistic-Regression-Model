{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Assignment\n",
    "\n",
    "© Rashed Iqbal <br>\n",
    "No part of this assignment could be used for any purposes other than for which it is intended (that is as an assignment workbook). <br>\n",
    "\n",
    "This assignment is based upon Logistic Regression slides discussed in the class during session: \n",
    "\n",
    "- Rename this iPython notebook to yourlastname_logitreg.ipynb\n",
    "- There are different sections in the assignment in this notebook where you will be writing code. Such places are indicated by block enclosed in START CODE HERE and END CODE HERE. In your submitted assignment, you will need to put your code ONLY in these blocks.\n",
    "- After each section, there are one or more cells that checks your code by executing a command. You should get the answer indicated. \n",
    "- Number of lines of codes are for guidelines. You may exeed the number specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "#### Assignment 1: \n",
    "Write a function called loss that takes two parameters *y* and *y<sup>^</sup>*\n",
    "Here y is the actual value and yhat is the prediction of the outcome\n",
    "\n",
    "The function returns the logistic loss -( (1-*y*)log(1-*y<sup>^</sup>*) + *y*log(*y<sup>^</sup>*))\n",
    "\n",
    "This function will return loss for a single training example. We will use this function to \n",
    "determine cost function while calling it for NumPy vectors. \n",
    "\n",
    "In the code, we will use y and yhat to represent *y* and *y<sup>^</sup>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16251892949777494"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "import math\n",
    "def loss(y, yhat):\n",
    "### START CODE HERE ### (≈ 1-5 lines of code)\n",
    "    loss = -((1 - y) * np.log(1 - yhat) + y * np.log(yhat))\n",
    "    return(loss)\n",
    "### END CODE HERE ###\n",
    "loss(1, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for y = 1 and yhat = 0.85 is equal to: 0.16252\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "yhat = 0.85\n",
    "print(\"Loss for y = {} and yhat = {} is equal to: {:1.5f}\".format(y, yhat, loss(y, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 1: \n",
    "###### You should get the following result\n",
    "Loss for y = 1 and yhat = 0.85 is equal to: 0.16252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "In Logistic Regression we use Sigmoid activation function. \n",
    "#### Assignment 2: \n",
    "Write a function called activation() that takes *y<sup>^</sup>* and returns 1/(1+ *e<sup>-yhat</sup>*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70056714247397289"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def activation(yhat):    \n",
    "### START CODE HERE ### (≈ 1-5 lines of code)\n",
    "    result = 1 / (1 + np.exp(-yhat))\n",
    "    return result\n",
    "### END CODE HERE ###\n",
    "activation(0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8ZtxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223fc4dba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.array(np.arange(-10,10,0.1))\n",
    "zsig = activation(z)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(z, zsig)\n",
    "plt.show()\n",
    "#print(\"Output of Activation Function on Z:\", zsig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 2: \n",
    "###### Your graph should be similar to the one below \n",
    "<img src=\"sigmoid.png\" style=\"float:left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data \n",
    "\n",
    "#### Assignment 3: \n",
    "In this assignment you will prepare input data. You will create a feature matrix X of shape (4, 3). Note that these are three training examples for four features \n",
    "\n",
    "1 &nbsp; &nbsp; &nbsp; 2 &nbsp; &nbsp; &nbsp; 1<br>\n",
    "1 &nbsp; &nbsp; &nbsp; 1 &nbsp; &nbsp; &nbsp; 0<br>\n",
    "1 &nbsp; &nbsp; &nbsp; 2 &nbsp; &nbsp; &nbsp; 1<br>\n",
    "1 &nbsp; &nbsp; &nbsp; 0 &nbsp; &nbsp; &nbsp; 2<br>\n",
    "\n",
    "Next you will create an outcome vector Y of shape (1, 4): <br>\n",
    "[ 0 &nbsp; &nbsp; &nbsp; 1 &nbsp; &nbsp; &nbsp; 0 ]\n",
    "\n",
    "- Both of the above will be numpy arrays. Make sure your shapes are correct.\n",
    "- Variables number of training examples *m* and number of features *n* are defined below. Use them in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "# training examples\n",
    "m = 3\n",
    "# number of features\n",
    "n = 4\n",
    "\n",
    "### START CODE HERE ### (≈ 2-5 lines of code)\n",
    "# This is the feature matrix X where n features of each of m training \n",
    "# examples are stacked vertically (n x m).\n",
    "\n",
    "# Solution 1\n",
    "X = np.zeros((n,m), dtype=int)\n",
    "X[0] = [1, 2, 1]\n",
    "X[1] = [1, 1, 0]\n",
    "X[2] = [1, 2, 1]\n",
    "X[3] = [1, 0, 2]\n",
    "\n",
    "# Solution 2\n",
    "X = np.array([1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2]).reshape(n, m)\n",
    "\n",
    "# This is the outcome (or dependent variable) Y. Note that shape of \n",
    "# this matrix is (1 x m)\n",
    "\n",
    "# Solution 1\n",
    "Y = np.zeros((1,m), dtype=int)\n",
    "Y[0] = [0, 1, 0]\n",
    "\n",
    "# Solution 2\n",
    "Y = np.array([0, 1, 0]).reshape(1, m)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=\n",
      " [[1 2 1]\n",
      " [1 1 0]\n",
      " [1 2 1]\n",
      " [1 0 2]]\n",
      "\n",
      "Y=\n",
      " [[0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X=\\n\", X)\n",
    "print(\"\\nY=\\n\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 3: \n",
    "###### Your output should be:\n",
    "\n",
    "X= <br>\n",
    " [[1&nbsp; &nbsp;2&nbsp; &nbsp;1] <br>\n",
    " [1&nbsp; &nbsp;1&nbsp; &nbsp;0] <br>\n",
    " [1&nbsp; &nbsp;2&nbsp; &nbsp;1] <br>\n",
    " [1&nbsp; &nbsp;0&nbsp; &nbsp;2]]\n",
    "\n",
    "Y=\n",
    " [[0&nbsp; &nbsp;1&nbsp; &nbsp;0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization  \n",
    "\n",
    "#### Assignment 4: \n",
    "In this assignment, you will:\n",
    "- create and initialize W and b to ones. Here, W is the (1,n) shape weight vector and b is the scalar bias.  \n",
    "- create and initialize J and Yhat to zeros. J is cost function vector of size (1,h) that will hold cost function for each iteration. Yhat is the (1,m) vector to hold prediction for all training examples. \n",
    "- Note that number of iterations h and the learning rate alpha have been initialized for you. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterations\n",
    "h = 100000\n",
    "alpha = 0.05\n",
    "\n",
    "### START CODE HERE ### (≈ 2-5 lines of code)\n",
    "# Model Parameters\n",
    "b = 1\n",
    "W = np.zeros([1, n])\n",
    " \n",
    "# Initialization of J and Yhat\n",
    "J = np.zeros([1, h])\n",
    "Yhat = np.zeros([1, m])\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W: (1, 4)\n",
      "Shape of J: (1, 100000)\n",
      "Sum of all elements of W: 0.0\n",
      "Sum of all elements of J: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of W:\", W.shape)\n",
    "print(\"Shape of J:\", J.shape)\n",
    "print(\"Sum of all elements of W:\", np.sum(W))\n",
    "print(\"Sum of all elements of J:\", np.sum(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 4: \n",
    "###### You should get the following results\n",
    "Shape of W: (1, 4) <br>\n",
    "Shape of J: (1, 100000) <br>\n",
    "Sum of all elements of W: 0.0 <br>\n",
    "Sum of all elements of J: 0.0 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Logistic Regression Using Loops\n",
    "In this assignment you will use loops to implement Logistics. Your implementation may vary but below is a possible list of loops:\n",
    "\n",
    "- There will be an outer most loop for iterations of Gradient Descent.\n",
    "- There will be a second loop for determining predictions and cost function over \n",
    "- There will be multiple innner loops for summing over weights \n",
    "\n",
    "#### Assignment 5: \n",
    "Implement Logistic Regression/Gradient Descent using loops.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(h):\n",
    "### START CODE HERE ### (≈ 20-30 lines of code)\n",
    "    dJdb = 0\n",
    "    dJdW = np.zeros([1, n])\n",
    "    dY = np.zeros([1, m])\n",
    "    for k in range(n):\n",
    "        dJdW[0, k] = 0\n",
    "    for i in range(m):\n",
    "        Yhat[0, i] = 0\n",
    "        for k in range(n):\n",
    "            Yhat[0, i] = Yhat[0, i] + W[0, k] * X[k, i]\n",
    "        Yhat[0, i] = Yhat[0, i] + b\n",
    "        Yhat[0, i] = 1 / (1 + np.exp(-Yhat[0, i]))\n",
    "        J[0, j] = J[0, j] + (Y[0, i] * np.log(Yhat[0, i]) + (1 - Y[0, i]) * np.log(1 - Yhat[0, i]))\n",
    "        dY[0, i] = Yhat[0, i] - Y[0, i]\n",
    "        dJdb = dJdb + dY[0, i]\n",
    "        for k in range(n):\n",
    "            dJdW[0, k] = dJdW[0, k] + dY[0, i] * X[k, i]\n",
    "    dJdb = dJdb / m\n",
    "    for k in range(n):\n",
    "        dJdW[0, k] = dJdW[0, k] / m\n",
    "    J[0, j] = -J[0, j] / m\n",
    "    b = b - alpha * dJdb\n",
    "    for k in range(n):\n",
    "        W[0, k] = W[0, k] - alpha * dJdW[0, k] \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.00038577170351032734\n",
      "b = -1.794089512132135\n",
      "W =  [[ 2.89098637 -2.11039808  2.89098637 -9.16285683]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Jcost = {}\".format(J[0,h-1]))\n",
    "print(\"b = {}\".format(b))\n",
    "print(\"W = \", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 4 (first check): \n",
    "###### You should get the following results\n",
    "\n",
    "Jcost = 0.00038577170351032734 <br>\n",
    "b = -1.794089512132135 <br>\n",
    "W =  [[ 2.89098637 &nbsp; -2.11039808 &nbsp; 2.89098637 &nbsp; -9.16285683]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGe6SNIL+P7tC7THrjuXSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223fcbc2c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(J[0,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 4 (second check): \n",
    "###### Your graph should be similar to the one below \n",
    "<img src=\"costfunc.png\" style=\"float:left\" height=\"200\" width=\"400\";>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Logistic Regression Using Linear Algebra (Matrix Operations)\n",
    "In this assignment you will use linear algebra to implement Logistics. Your implementation \n",
    "may vary but below is a possible list:\n",
    "\n",
    "- There will be an outer most loop for iterations of Gradient Descent as the case with implementation using loops. This will be the ONLY loop in this implmentation.\n",
    "- Use matrix operations to implement the remaining operations.\n",
    "\n",
    "#### Assignment 6: \n",
    "Implement Logistic Regression/Gradient Descent using Linear Algebra.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization: \n",
    "Use the same code block from Assignment 4 below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterations\n",
    "h = 100000\n",
    "alpha = 0.05\n",
    "\n",
    "### START CODE HERE ### (≈ 2-5 lines of code)\n",
    "# Model Parameters\n",
    "b = 1\n",
    "W = np.zeros([1, n])\n",
    "\n",
    "# Initialization of J and Yhat\n",
    "J = np.zeros([1, h])\n",
    "Yhat = np.zeros([1, m])\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression using Linear Algebra: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for g in range(h):\n",
    "### START CODE HERE ### (≈ 4-10 lines of code)\n",
    "    dJdz = np.zeros([1, m])\n",
    "    dJdw = np.zeros([1, n])\n",
    "    B = np.ones([1, m])\n",
    "    Yhat = 1 / (1 + np.exp(-(np.dot(W, X) + b * B)))\n",
    "    J[0, g] = (-1 / m) * np.sum((Y * np.log(Yhat)) + (1 - Y) * np.log(1 - Yhat))\n",
    "    dJdz = Y - Yhat\n",
    "    dJdb = (-1 / m) * np.sum(dJdz)\n",
    "    dJdw = (-1 / m) * np.dot(dJdz, X.T)\n",
    "    b = b - alpha * dJdb\n",
    "    W = W - alpha * dJdw\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.00038577170351032734\n",
      "b = -1.7940895121321347\n",
      "W =  [[ 2.89098637 -2.11039808  2.89098637 -9.16285683]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Jcost = {}\".format(J[0,h-1]))\n",
    "print(\"b = {}\".format(b))\n",
    "print(\"W = \", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Assignment 6: \n",
    "###### You should get the following results\n",
    "\n",
    "Jcost = 0.00038577170351032734 <br>\n",
    "b = -1.794089512132135 <br>\n",
    "W =  [[ 2.89098637 &nbsp; -2.11039808 &nbsp; 2.89098637 &nbsp; -9.16285683]]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
